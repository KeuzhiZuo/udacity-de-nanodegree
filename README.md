# Udacity Data Engineer Nanodegree
This repo contains all the exercises and projects from Udacity [Data Engineer Nanodegree](https://www.udacity.com/course/data-engineer-nanodegree--nd027). 
Folders with the lesson names contain all the exercises from that lesson, and folders named as project # are the project related documents. 

## Project 1 - Data Modeling with Postgres
A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. 
Their current data resides in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app, but there is not an easy way to query data. <br>
This project offers a solution to the above issue with a database schema and ETL pipeline. Please click [HERE](https://github.com/KeuzhiZuo/udacity-de-nanodegree-wip/tree/main/project_1) to view more details about this project.

## Project 2 - Data Modeling with Apache Cassandra
A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. The analysis team is particularly interested in understanding what songs users are listening to. Currently, there is no easy way to query the data to generate the results, since the data reside in a directory of CSV files on user activity on the app. <br> 
This project offers a solution to create a Apache Cassandra database which can create queries on song data to answer questions.
Please click [HERE](https://github.com/KeuzhiZuo/udacity-de-nanodegree-wip/tree/main/project_2) to view more details about this project.

## Project 3 - Data Warehouse
Sparkify has grown their user base and song database and want to move their processes and data onto the cloud. The data resides in S3, in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app. In this project, I am building an ETL pipeline that extracts Sparkify's data from S3, stages them in Redshift, and transforms data into a set of dimensional tables for their analytics team to continue finding insights in what songs their users are listening to.
This project offers a solution to extract data from S3 and create queries on song data to answer questions.
Please click [HERE](https://github.com/KeuzhiZuo/udacity-de-nanodegree-wip/tree/main/project_3) to view more details about this project.

## Project 4 - Data Lake
In this project, Sparkify wants to move data warehouse to data lake. Their data resides in S3, in a directory of JSON logs on user activity on the app, as well as a diretory with JSON metadata on the songs in their app. As a data engineer, I am going to build a etl pupeline that extracts their data from S3, process them with Spark, and loads the data back into S3 as a set of dimensional tables. This will allow Sparkify's analytics to explore more about the data.
Please click [HERE](https://github.com/KeuzhiZuo/udacity-de-nanodegree-wip/tree/main/project_4) to view more details about this project.

## Project 5 - Data Pipelines 
In this project, I am using airflow to build four different operators that will stage the data, transform the data, and run checks on data quality.
By utilizing Airflow's built-in functionalities as connections and hooks as much as possible, I let Airflow do all the heavy-lifting when it is possible.
Please click [HERE](https://github.com/KeuzhiZuo/udacity-de-nanodegree-wip/tree/main/project_5) to view more details about this project.

## Project 6 - Capstone
updating...

##### Note: 
More projects will be added to this repo while I make more progress on this course, and more info will be continuously added to this readme file.
